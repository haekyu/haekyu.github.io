[
  {
    "id": "neuromapper",
    "title": "NeuroMapper: In-browser Visualizer for Neural Network Training",
    "author": [
      "Zhiyan Zhou",
      "<a href='https://www.kevinyli.com/'>Kevin Li</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "Megan Dass",
      "<a href='https://www.austinpwright.com/'>Austin P. Wright</a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Visualization Conference (VIS), 2022",
    "links": {
      "paper": "",
      "demo": "https://poloclub.github.io/NeuroMapper/"
    },
    "bibtex": [
      "@article{zhou2022neuromapper,",
      "title = {NeuroMapper: In-browser Visualizer for Neural Network Training},",
        "author = {Zhou, Zhiyan AND Li, Kevin AND Park, Haekyu AND Dass, Megan AND Wright, Austin AND Das, Nilaksh AND Chau, Duen Horng},",
        "booktitle = {IEEE Visualization Conference, (VIS)},",
        "year = {2022},",
      "}"
    ],
    "detail": [
      "We present our ongoing work NeuroMapper, an in-browser visualization",
      "tool that helps machine learning (ML) developers interpret the evolution", 
      "of a model during training, providing a new way to monitor the training", 
      "process and visually discover reasons for suboptimal training. While", 
      "most existing deep neural networks (DNNs) interpretation tools are", 
      "designed for already-trained model, NeuroMapper scalably visualizes", 
      "the evolution of the embeddings of a model’s blocks across training", 
      "epochs, enabling real-time visualization of 40,000 embedded points.", 
      "To promote the embedding visualizations’ spatial coherence across epochs,",
      "NeuroMapper adapts AlignedUMAP, a recent nonlinear dimensionality", 
      "reduction technique to align the embeddings. With NeuroMapper, users", 
      "can explore the training dynamics of a Resnet-50 model, and adjust the", 
      "embedding visualizations’ parameters in real time. NeuroMapper is", 
      "open-sourced at <a href='https://github.com/poloclub/NeuroMapper'>https://github.com/poloclub/NeuroMapper</a>",
      "and runs in all modern web browsers. A demo of the tool in action is available at:",
      "<a href='https://poloclub.github.io/NeuroMapper/'>https://poloclub.github.io/NeuroMapper</a>."
    ]
  },
  {
    "id": "misvis_vis",
    "title": "Explaining Website Reliability by Visualizing Hyperlink Connectivity",
    "author": [
      "<a href='https://ligi214.github.io'>Seongmin Lee</a>",
      "Sadia Afroz",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "Vibhor Sehgal",
      "Ankit Peshin",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Visualization Conference (VIS), 2022",
    "links": {
      "paper": ""
    },
    "bibtex": [
      "@article{lee2022explaining,",
      "title = {Explaining Website Reliability by Visualizing Hyperlink Connectivity},",
        "author = {Lee, Seongmin AND Afroz, Sadia AND Park, Haekyu AND Wang, Zijie J. AND Shaikh, Omar AND Sehgal, Vibhor AND Peshin, Ankit AND Chau, Duen Horng},",
        "booktitle={IEEE Visualization Conference, (VIS)},",
        "year = {2022},",
      "}"
    ],
    "detail": [
      "MISVIS helps users assess a website’s reliability and understand",
      "how the site may be involved in spreading false information by", 
      "visualizing its hyperlink connectivity. When a user visits a website,",
      "MISVIS is displayed interstitially over the website, blurring its", 
      "contents and blocking user interactions. The MISVIS user interface", 
      "consists of (A) a Header message about the reliability of the website", 
      "being visited by the user, (B) brief Explanation about how to interpret",
      "the MISVIS visualization, and (C) the Main Window that visualizes the", 
      "connectivity of the visited website in two coordinated views: Graph View", 
      "and Summary View. (1) The View shows how the website connects to other", 
      "websites via hyperlinks. Dots are websites, and edges are hyperlinks;", 
      "the site being visited is shown in the middle. MISVIS visualizes the",
      "information flow among sites through animation. (2) The Summary View",
      "shows the site’s overall reliability by summarizing the reliability of",
      "its connected sites. In both views, controversial sites are shown in",
      "orange, verified in purple, and unlabeled in gray."
    ]
  },
  {
    "id": "detectordetective",
    "title": "DetectorDetective: Investigating the Effects of Adversarial Examples on Object Detectors",
    "author": [
      "Sivapriya Vellaichamy",
      "Matthew Hull",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='https://shengyun-peng.github.io'>Sheng-Yun Peng</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "Conference on Computer Vision and Pattern Recognition (CVPR), Demo, 2022",
    "links": {
      "demo": "https://poloclub.github.io/detector-detective",
      "paper": "https://ieeexplore.ieee.org/document/9879862"
    },
    "bibtex": [
      "@inproceedings{vellaichamy2022cvpr,",
        "title={DetectorDetective: Investigating the Effects of Adversarial Examples on Object Detectors}",
        "author={Vellaichamy, Sivapriya and Hull, Matthew and Wang, Zijie J. and Das, Nilaksh and Peng, Sheng-Yun and Park, Haekyu and Chau, Duen Horng},",
        "booktitle={CVPR}",
        "year={2022}",
      "}"
    ],
    "detail": [
      "With deep learning based systems performing exceedingly well in",
      "many vision-related tasks, a major concern with their widespread", 
      "deployment especially in safety-critical appli-cations is their",
      "susceptibility to adversarial attacks. We propose DetectorDetective,",
      " an interactive visual tool that aims to help users better understand",
      "the behaviors of a model as adversarial images journey through an object",
      "detector. DetectorDetective enables users to easily learn about how",
      "the three key modules of the Faster R-CNN object detector —",
      "Feature Pyramidal Network, Region Proposal Network, and Region",
      "Of Interest Head — respond to a user-selected benign image and its",
      "adversarial version. Visualizations about the progressive changes",
      "in the intermediate features among such modules help users gain",
      "insights into the impact of adversarial attacks, and perform ",
      "side-by-side comparisons between the benign and adversarial responses.",
      " Furthermore, DetectorDetective displays saliency maps for the", 
      "input images to comparatively highlight image regions that contribute",
      "to attack success. DetectorDetective complements adversarial machine",
      "learning research on object detection by providing a user-friendly",
      "interactive tool for inspecting and understanding model responses."
    ]
  },
  {
    "id": "misvis_chi",
    "title": "MisVis: Explaining Web Misinformation Connections via Visual Summary",
    "author": [
      "<a href='https://ligi214.github.io'>Seongmin Lee</a>",
      "Sadia Afroz",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "Vibhor Sehgal",
      "Ankit Peshin",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "CHI Conference on Human Factors in Computing Systems Extended Abstracts, 2022",
    "links": {
      "demo": "https://poloclub.github.io/MisVis/",
      "paper": "https://ligi214.github.io/assets/publication_pdf/22_chi_misvis_publication.pdf"
    },
    "bibtex": [
      "@article{lee2022misvis,",
        "doi = {10.1145/3491101.3519711},",
        "author = {Lee, Seongmin AND Afroz, Sadia AND Park, Haekyu AND Wang, Zijie J. AND Shaikh, Omar AND Sehgal, Vibhor AND Peshin, Ankit AND Chau, Duen Horng},",
        "publisher = {ACM},",
        "booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems}",
        "title = {{MisVis}: Explaining Web Misinformation Connections via Visual Summary},",
        "year = {2022},",
      "}"
    ],
    "detail": [
      "Identifying and raising awareness about web misinformation is crucial",
      "as the Internet has become a major source of information for many people.",
      "We introduce MisVis, a web-based interactive tool that helps users better assess misinformation websites",
      "and understand their connections with other misinformation sites through visual explanations.",
      "Different from the existing techniques that primarily only focus on alerting users of misinformation,", 
      "MisVis provides new ways to visualize how the site is involved in spreading information on the web and social media.",
      "Through MisVis, we con- tribute novel interactive visual design: Summary View helps users understand a site's overall reliability",
      "by showing the distributions of its linked websites; Graph View presents users with the connection details of how a site is linked", 
      "to other misinformation websites. In collaboration with researchers at a large security company, we are working to deploy MisVis", 
      "as a web browser extension for broader impact."
    ]
  },
  {
    "id": "neurocartography",
    "title": "NeuroCartography: Scalable Automatic Visual Summarization of Concepts in Deep Neural Networks",
    "author": [
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='http://http://www.rahulduggal.com/'>Rahul Duggal</a>",
      "<a href='https://www.austinpwright.com/'>Austin P. Wright</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Visualization Conference (VIS), Virtual, 2021",
    "links": {
      "demo": "https://poloclub.github.io/neuro-cartography/",
      "paper": "https://arxiv.org/abs/2108.12931"
    },
    "bibtex": [
      "@article{park2021neurocartography,",
      "title={Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks},",
      "author={Park, Haekyu and Das, Nilaksh and Duggal, Rahul and Wright, Austin P and Shaikh, Omar and Hohman, Fred and Chau, Duen Horng Polo},",
      "journal={IEEE Transactions on Visualization and Computer Graphics},",
      "volume={28},",
      "number={1},",
      "pages={813--823},",
      "year={2021},",
      "publisher={IEEE}",
      "}"
    ],
    "detail": [
      "Existing research on making sense of deep neural networks",
      "often focuses on neuron-level interpretation, which may not",
      "adequately capture the bigger picture of how concepts are",
      "collectively encoded by multiple neurons.",
      "We present NeuroCartography, an interactive system that scalably",
      "summarizes and visualizes concepts learned by neural networks.",
      "It automatically discovers and groups neurons that detect the same",
      "concepts, and describes how such neuron groups interact to form", 
      "higher-level concepts and the subsequent predictions.",
      "NeuroCartography introduces two scalable summarization techniques:",
      "(1) neuron clustering groups neurons based on the semantic similarity",
      "of the concepts detected by neurons (e.g., neurons detecting",
      "\"dog faces\" of different breeds are grouped);",
      "and (2) neuron embedding encodes the associations between related",
      "concepts based on how often they co-occur (e.g., neurons detecting",
      "\"dog face\" and \"dog tail\" are placed closer in the embedding",
      "space). Key to our scalable techniques is the ability to efﬁciently",
      "compute all neuron pairs’ relationships, in time linear to the",
      "number of neurons instead of quadratic time.",
      "NeuroCartography scales to large data, such as the ImageNet",
      "dataset with 1.2M images. The system’s tightly coordinated",
      "views integrate the scalable techniques to visualize the concepts",
      "and their relationships, projecting the concept associations to a",
      "2D space in Neuron Projection View, and summarizing neuron clusters",
      "and their relationships in Graph View. Through a large-scale human",
      "evaluation, we demonstrate that our technique discovers neuron groups",
      "that represent coherent, human-meaningful concepts. And through usage",
      "scenarios, we describe how our approaches enable interesting and",
      "surprising discoveries, such as concept cascades of related and",
      "isolated concepts. The NeuroCartography visualization runs in modern",
      "browsers and is open-sourced."
    ]
  },
  {
    "id": "recast",
    "title": "RECAST: Enabling User Recourse and Interpretability of Toxicity Detection Models with Interactive Visualization",
    "author": [
      "<a href='https://www.austinpwright.com/'>Austin P. Wright</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://willepperson.com/'>Will Epperson</a>",
      "Muhammed Ahmed",
      "Stephane Pinel",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>",
      "<a href='https://www.cc.gatech.edu/~dyang888/'>Diyi Yang</a>"
    ],
    "venue": "24th ACM Conference on Computer-Supported Cooperative Work & Social Computing (<a href='https://cscw.acm.org/2021/'>CSCW</a>), 2021.",
    "links": {
      "paper": "https://arxiv.org/abs/2102.04427"
    },
    "bibtex": [
      "@article{wright2020recast,",
      "title={{RECAST: Enabling User Recourse and Interpretability of Toxicity Detection Models with Interactive Visualization}},",
      "author={Austin P. Wright and Omar Shaikh and Haekyu Park and Will Epperson and Muhammed Ahmed and Stephane Pinel and Diyi Yang and Duen Horng (Polo) Chau},",
      "booktitle={ACM Conference on Computer-Supported Cooperative Work & Social Computing (CSCW)},",
      "year={2021}",
      "}"
    ],
    "detail": [
      "With the widespread use of toxic language online,",
      "platforms are increasingly using automated systems",
      "that leverage advances in natural language processing",
      "to automatically flag and remove toxic comments.",
      "However, most automated systems -- when detecting and moderating",
      "toxic language -- do not provide feedback to their users,",
      "let alone provide an avenue of recourse for these users to",
      "make actionable changes. We present our work, RECAST,",
      "an interactive, open-sourced web tool for visualizing",
      "these models' toxic predictions, while providing alternative",
      "suggestions for flagged toxic language. Our work also provides",
      "users with a new path of recourse when using these automated", 
      "moderation tools. RECAST highlights text responsible for",
      "classifying toxicity, and allows users to interactively",
      "substitute potentially toxic phrases with neutral alternatives.",
      "We examined the effect of RECAST via two large-scale user",
      "evaluations, and found that RECAST was highly effective at",
      "helping users reduce toxicity as detected through the model.",
      "Users also gained a stronger understanding of the underlying",
      "toxicity criterion used by black-box models, enabling",
      "transparency and recourse. In addition, we found that when",
      "users focus on optimizing language for these models instead", 
      "of their own judgement (which is the implied incentive and goal",
      "of deploying automated models), these models cease to be",
      "effective classifiers of toxicity compared to human annotations.",
      "This opens a discussion for how toxicity detection models work",
      "and should work, and their effect on the future of online",
      "discourse."
    ]
  },
  {
    "id": "skeletonvis",
    "title": "SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models",
    "author": [
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "Anindya S. Paul",
      "Pruthvi Perumalla",
      "Zhiyan Zhou",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "<a href='https://aaai.org/Conferences/AAAI-21/'>AAAI</a>, Demo, Virtual, 2021.",
    "links": {
      "demo": "https://poloclub.github.io/skeleton-vis/",
      "paper": "https://arxiv.org/abs/2101.10586"
    },
    "bibtex": [
      "@article{park2021skeletonvis,",
      "title={{SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models}},",
      "author={Park, Haekyu and Wang, Zijie J. and Das, Nilaksh and Paul, Anindya S. and Perumalla, Pruthvi and Zhou, Zhiyan and Chau, Duen Horng},",
      "booktitle={AAAI, Demo},",
      "year={2021}",
      "}"
    ],
    "detail": [
      "Skeleton-based human action recognition technologies are",
      "increasingly used in video based applications, such as",
      "home robotics, healthcare on aging population, and",
      "surveillance. However, such models are vulnerable to",
      "adversarial attacks, raising serious concerns for their",
      "use in safety-critical applications. To develop an",
      "effective defense against attacks, it is essential to",
      "understand how such attacks mislead the pose detection",
      "models into making incorrect predictions. We present",
      "SkeletonVis, the first interactive system that visualizes",
      "how the attacks work on the models to enhance human",
      "understanding of attacks."
    ]
  },
  {
    "id": "bluff",
    "title": "Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks",
    "author": [
      "<a href='http://nilakshdas.com'>Nilaksh Das*</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u>*</a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://www.robfirstman.com/'>Robert Firstman</a>",
      "<a href='https://www.linkedin.com/in/emily-rogers-1a828598'>Emily Rogers</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Visualization Conference, (<a href='http://ieeevis.org/year/2020/welcome'>VIS</a>), Salt Lake City, UT, USA, 2020. <br>* Authors contributed equally.",
    "links": {
      "demo": "https://poloclub.github.io/bluff",
      "paper": "https://arxiv.org/abs/2009.02608"
    },
    "bibtex": [
      "@article{das2020bluff,",
      "title={{Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks}},",
      "author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},",
      "booktitle={IEEE Visualization Conference (VIS)},",
      "year={2020}",
      "}"
    ],
    "detail": [
      "Bluff is an interactive system for visualizing,",
      "characterizing, and deciphering adversarial attacks on",
      "vision-based neural networks.",
      "Bluff allows people to flexibly visualize and compare the",
      "activation pathways for benign and attacked images,",
      "revealing mechanisms that adversarial attacks employ to",
      "inflict harm on a model.",
      "Bluff is open-sourced and runs in modern web browsers."
    ]
  },
  {
    "id": "cnnexplainer",
    "title": "CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization",
    "author": [
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://www.linkedin.com/in/robert-turko/'>Robert Turko</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://minsuk.com/'>Minsuk Kahng</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Conference on Visual Analytics Science and Technology, (<a href='http://ieeevis.org/year/2020/welcome'>VAST</a>), Salt Lake City, UT, USA, 2020.",
    "links": {
      "demo": "https://poloclub.github.io/cnn-explainer",
      "paper": "https://arxiv.org/abs/2004.15004"
    },
    "bibtex": [
      "@article{wangCNNExplainerLearning2020,",
      "title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},",
      "shorttitle = {{{CNN Explainer}}},",
      "author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},",
      "year={2020},",
      "journal={IEEE Conference on Visual Analytics Science and Technology (VAST)},",
      "publisher={IEEE}",
      "}"
    ],
    "detail": [
      "We present CNN Explainer, an interactive visualization tool",
      "designed for non-experts to learn and examine convolutional",
      "neural networks (CNNs), a foundational deep learning",
      "model architecture. Our tool addresses key challenges that",
      "novices face while learning about CNNs, which we identify ",
      "from interviews with instructors and a survey with past ",
      "students. CNN Explainer tightly integrates a model overview ",
      "that summarizes a CNN’s structure, and on-demand, dynamic ",
      "visual explanation views that help users understand the ",
      "underlying components of CNNs. Through smooth transitions ",
      "across levels of abstraction, our tool enables users to ",
      "inspect the interplay between low-level mathematical ",
      "operations and high-level model structures. A qualitative",
      "user study shows that CNN EXPLAINER helps users more ",
      "easily understand the inner workings of CNNs, and is ",
      "engaging and enjoyable to use. We also derive design ",
      "lessons from our study. Developed using modern web ",
      "technologies, CNN EXPLAINER runs locally in users’ web ",
      "browsers without the need for installation or specialized ",
      "hardware, broadening the public’s education access to ",
      "modern deep learning techniques."
    ]
  },
  {
    "id": "human-ai-survey",
    "title": "A Comparative Analysis of Industry Human-AI Interaction Guidelines",
    "author": [
      "<a href='https://www.austinpwright.com/'>Austin P. Wright</a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://gracegsy.github.io/'>Grace Guo</a>",
      "<a href='https://www.vis.uni-konstanz.de/mitglieder/sperrle/'>Fabian Sperrle</a>",
      "<a href='https://el-assady.com/'>Mennatallah El-Assady</a>",
      "<a href='https://va.gatech.edu/endert/'>Alex Endert</a>",
      "<a href='https://www.vis.uni-konstanz.de/en/members/keim'>Daniel Keim</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Visualization Conference, Workshop on Trust and Expertise in Visual Analytics (TREX), Salt Lake City, UT, USA, 2020.",
    "links": {
      "paper": "https://arxiv.org/abs/2010.11761"
    },
    "bibtex": [
      "@article{wrightComparativeAnalysisIndustry2020,",
      "title = {A {{Comparative Analysis}} of {{Industry Human}}-{{AI Interaction Guidelines}}},",
      "author = {Wright, Austin P. and Wang, Zijie J. and Park, Haekyu and Guo, Grace and Sperrle, Fabian and {El-Assady}, Mennatallah and Endert, Alex and Keim, Daniel and Chau, Duen Horng},",
      "year={2020},",
      "booktitle={IEEE Visualization Conference, Workshop on Trust and Expertise in Visual Analytics (TREX)},",
      "eprint={arXiv:2010.11761}",
      "}"
    ],
    "detail": [
      "With the recent release of AI interaction guidelines from Apple, Google, and Microsoft, there is clearly interest in understanding the best practices in human-AI interaction. However, industry standards are not determined by a single company, but rather by the synthesis of knowledge from the whole community. We have surveyed all of the design guidelines from each of these major companies and developed a single, unified structure of guidelines, giving developers a centralized reference. We have then used this framework to compare each of the surveyed companies to find differences in areas of emphasis. Finally, we encourage people to contribute additional guidelines from other companies, academia, or individuals, to provide an open and extensible reference of AI design guidelines at https://ai-open-guidelines.readthedocs.io/en/latest/."
    ]
  },
  {
    "id": "argo",
    "title": "Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers",
    "author": [
      "<a href='https://rsli.github.io/'>Siwei Li</a>",
      "<a href='https://www.linkedin.com/in/frank-zhou-b19515159/'>Zhiyan Zhou</a>",
      "Anish Upadhayay",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "<a href='https://scottfreitas.com'>Scott Freitas</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "Susanta Routray",
      "Matthew Hull",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "ACM International Conference on Information and Knowledge Management, (<a href='https://www.cikm2020.org/'>CIKM</a>), Resource Track, Online, 2020.",
    "links": {
      "demo": "https://poloclub.github.io/argo-graph-lite",
      "paper": "https://poloclub.github.io/papers/20-cikm-argolite.pdf"
    },
    "bibtex": [
      "@inproceedings{li2020argo,",
      "title={{Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers}},",
      "author={Li, Siwei and Zhou, Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu and Wang, Zijie J and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},",
      "booktitle={Proceedings of the International Conference on Information and Knowledge Management},",
      "year={2020},",
      "organization={ACM}",
      "}"
    ],
    "detail": [
      "Graph data have become increasingly common. Visualizing them helps people better understand relations among entities. We have developed Argo Lite, a new in-browser interactive graph exploration and visualization tool. Argo Lite enables users to publish and share interactive graph visualizations as URLs and embedded web widgets. Argo Lite works across devices and platforms, leveraging WebGL for high-performance rendering. Argo Lite has been used by over 1,000 students at Georgia Tech’s Data and Visual Analytics class."
    ]
  },
  {
    "id": "massif",
    "title": "Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning",
    "author": [
      "<a href='http://nilakshdas.com'>Nilaksh Das*</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u>*</a>",
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://www.robfirstman.com/'>Robert Firstman</a>",
      "<a href='https://www.linkedin.com/in/emily-rogers-1a828598'>Emily Rogers</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "ACM CHI Conference on Human Factors in Computing Systems (CHI), <a href='https://chi2020.acm.org/authors/late-breaking-works/'>Late-Breaking Works</a>, Honolulu, Hawaii, USA, 2020. <br>* Authors contributed equally.",
    "links": {
      "paper": "https://arxiv.org/abs/2001.07769"
    },
    "bibtex": [
      "@inproceedings{das2020massif,",
      "title={{Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning}},",
      "author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J. and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng (Polo)},",
      "booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},",
      "publisher={ACM},",
      "year={2020}",
      "}"
    ],
    "detail": [
      "We present Massif, an interactive tool for deciphering adversarial attacks. Massif identifies and interactively visualizes neurons and their connections inside a DNN that are strongly activated or suppressed by an adversarial attack. Massif provides both a high-level, interpretable overview of the effect of an attack on a DNN, and a low-level, detailed description of the affected neurons. These tightly coupled views in Massif help people better understand which input features are most vulnerable or important for correct predictions."
    ]
  },
  {
    "id": "cnn101",
    "title": "CNN 101: Interactive Visual Learning for Convolutional Neural Networks",
    "author": [
      "<a href='https://zijie.wang/'>Zijie J. Wang</a>",
      "<a href='https://www.linkedin.com/in/robert-turko/'>Robert Turko</a>",
      "<a href='https://oshaikh.com/'>Omar Shaikh</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://minsuk.com/'>Minsuk Kahng</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "ACM CHI Conference on Human Factors in Computing Systems (CHI), <a href='https://chi2020.acm.org/authors/late-breaking-works/'>Late-Breaking Works</a>, Honolulu, Hawaii, USA, 2020.",
    "links": {
      "paper": "https://arxiv.org/abs/2001.02004"
    },
    "bibtex": [
      "@inproceedings{wang_cnn_2020,",
      "title={{CNN} 101: {Interactive} {Visual} {Learning} for {Convolutional} {Neural} {Networks}},",
      "author={Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},",
      "booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},",
      "publisher={ACM},",
      "year={2020}",
      "}"
    ],
    "detail": [
      "CNN 101 is an interactive visualization system for explaining and teaching convolutional neural networks. Through tightly integrated interactive views, CNN 101 offers both overview and detailed descriptions of how a model works. Built using modern web technologies, CNN 101 runs locally in users' web browsers without requiring specialized hardware, broadening the public's education access to modern deep learning techniques."
    ]
  },
  {
    "id": "summit",
    "title": "Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations",
    "author": [
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='http://calebrob.com'>Caleb Robinson</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Transactions on Visualization and Computer Graphics (<a href='http://ieeevis.org/year/2019/welcome'>TVCG</a>), Vancouver, BC, Canada, 2020.",
    "links": {
      "demo": "https://fredhohman.com/summit",
      "paper": "https://arxiv.org/abs/1904.02323"
    },
    "bibtex": [
      "@article{hohman2020summit,",
      "title={{Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations}},",
      "author={Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng},",
      "journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},",
      "year={2020},",
      "publisher={IEEE}",
      "}"
    ],
    "detail": [
      "With Summit, users can scalably summarize and interactively interpret deep neural networks by visualizing what features a network detects and how they are related. For example, InceptionV1 accurately classifies images of tench (yellow-brown fish). However, Summit reveals surprising associations in the network (e.g., using parts of people) that contribute to its final outcome: the 'tench' prediction is dependent on an intermediate 'hands holding fish' feature, which is influenced by lower-level features like 'scales,' 'person,' and 'fish'."
    ]
  },
  {
    "id": "wiml-19",
    "title": "Visual Analytics for Interpretability on Deep Neural Networks",
    "author": [
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='http://calebrob.com'>Caleb Robinson</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "Women in Machine Learning Workshop (<a href='http://ieeevis.org/year/2019/welcome'>WiML</a>), co-located with NeurIPS 2019, Vancouver, BC, Canada, 2019."
  },
  {
    "id": "mlsploit2",
    "title": "MLsploit: A Framework for Interactive Experimentation with Adversarial Machine Learning Research",
    "author": [
      "<a href='http://nilakshdas.com'>Nilaksh Das</a>",
      "<a href='https://rsli.github.io'>Siwei Li</a>",
      "Chanil Jeon",
      "Jinho Jung",
      "Shang-Tse Chen",
      "Carter Yagemann",
      "Evan Downing",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "Evan Yang",
      "Li Chen",
      "Michael Kounavis",
      "Ravi Sahita",
      "David Durham",
      "Scott Buck",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>",
      "<a href='https://taesoo.kim'>Taesoo Kim</a>",
      "<a href='http://wenke.gtisc.gatech.edu'>Wenke Lee</a>"
    ],
    "venue": "ACM SIGKDD Conference on Konwledge Discovery and Data Mining (KDD), <a href='KDD Project Showcase, 2019, https://www.kdd.org/kdd2019/project-showcase'>KDD Project</a>, Anchorage, Alaska, USA, 2019.",
    "links": {
      "demo": "https://mlsploit.github.io",
      "paper": "https://www.kdd.org/kdd2019/docs/KDD2019_Showcase_2062.pdf"
    }
  },
  {
    "id": "neuraldivergence",
    "title": "NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions",
    "author": [
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://fredhohman.com'>Fred Hohman</a>",
      "<a href='https://www.cc.gatech.edu/~dchau/'>Duen Horng Chau</a>"
    ],
    "venue": "IEEE Pacific Visualization Symposium (<a href='http://research.cbs.chula.ac.th/pvis2019/home.aspx'>PacificVis</a>), Bangkok, Thailand, 2019.",
    "links": {
      "demo": "http://haekyu.com/neural-divergence",
      "paper": "https://arxiv.org/abs/1906.00332"
    },
    "bibtex": [
      "@inproceedings{park2019neuraldivergence,",
      "title={NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions},",
      "author={Park, Haekyu and Hohman, Fred and Chau, Duen Horng},",
      "booktitle={Poster, Pacific Visualization Symposium (PacificVis)},",
      "year={2019},",
      "publisher={IEEE}",
      "}"
    ],
    "detail": [
      "NeuralDivergence is an interactive visualization system that uses activation distributions as a high-level summary of what a model has learned. NeuralDivergence enables users to interactively summarize and compare activation distributions across layers, classes, and instances (e.g., pairs of adversarial attacked and benign images), helping them gain better understanding of neural network models."
    ]
  },
  {
    "id": "side",
    "title": "SIDE: Representation Learning in Signed Directed Networks",
    "author": [
      "<a href='http://junghwanjkim.com'>Junghwan Kim</a>",
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://jieunparklee.github.io'>Ji-Eun Lee</a>",
      "<a href='https://datalab.snu.ac.kr/~ukang/'>U Kang</a>"
    ],
    "venue": "The Web Conference (Previously known as <a href='https://www2018.thewebconf.org'>WWW</a>, World Wide Web Conference), Lyon, France, 2018.",
    "links": {
      "webpage": "https://datalab.snu.ac.kr/side",
      "paper": "https://datalab.snu.ac.kr/side/resources/side.pdf"
    },
    "bibtex": [
      "@inproceedings{KimPLK18,",
      "title={{SIDE: Representation Learning in Signed Directed Networks}},",
      "author={Kim, Junghwan and Park, Haekyu and Lee, Ji{-}Eun and Kang, U.},",
      "booktitle={Proceedings of the 2018 World Wide Web Conference on World Wide Web, {WWW}},",
      "year={2018},",
      "}"
    ],
    "detail": [
      "We propose SIDE, a network embedding algorithm for signed directed networks. Network embedding learns a mapping of each node to a vector. SIDE carefully formulates and optimizes likelihood over both direct and indirect signed connections. We provide socio-psychological interpretation for each component of likelihood function and prove linear scalability of our algorithm."
    ]
  },
  {
    "id": "mfrwr",
    "title": "A Comparative Study of Matrix Factorization and Random Walk with Restart in Recommender Systems",
    "author": [
      "<a href='https://haekyu.github.io'><u>Haekyu Park</u></a>",
      "<a href='https://datalab.snu.ac.kr/~jinhong/'>Jinhong Jung</a>",
      "<a href='https://datalab.snu.ac.kr/~ukang/'>U Kang</a>"
    ],
    "venue": "IEEE International Conference on Big Data (<a href='http://cci.drexel.edu/bigdata/bigdata2017/'>BigData</a>), Boston, MA, USA, 2017.",
    "links": {
      "webpage": "https://datalab.snu.ac.kr/mfrwr/",
      "paper": "https://arxiv.org/abs/1708.09088"
    },
    "bibtex": [
      "@inproceedings{Park17mfrwr,",
      "title={{A comparative study of matrix factorization and random walk with restart in recommender systems}},",
      "author={Park, Haekyu and Jung, Jinhong and Kang, U.},",
      "booktitle={{IEEE} International Conference on Big Data, {BigData}},",
      "year={2017},",
      "}"
    ],
    "detail": [
      "<ul>",
      "<li> <b>Main Question</b>:<br>",
      "Between matrix factorization (<b>MF</b>) or Random Walk with Restart (<b>RWR</b>),",
      "which method works better for recommender systems?",
      "<li> <b>Specific tasks</b>:<br>",
      "We compare MF and RWR for the following recommendation scenarios.",
      "<ul class='no-list work'>",
      "<li> Which method performs better when using <b>explicit feedback</b> data?</li> &rarr; MF is better.", 
      "<li> Which method performs better when using <b>implicit feedback</b> data?</li> &rarr; RWR is better.",
      "<li> Do global <b>bias</b> terms improve performance?</li> &rarr; Yes.",
      "<li> Which method performs better when exploiting global <b>bias</b> terms?</li> &rarr; MF is better.",
      "<li> Does <b>side information</b> enhance performance?</li> &rarr; Yes with explicit ratings, and No with implicit ratings.",
      "<li> Which method performs better when employing <b>side information</b>? </li> &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.",
      "<li> Which method solves the <b>cold start problem</b> better when employing <b>side data</b>? </li> &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.",
      "</ul>",
      "<li> <b>Discussion</b>:<br>",
      "What are the <b>reasons</b> for good or bad performance of MF and RWR in various settings of recommendations? Details are in Section 4.G in our paper. Please read that part!"
    ]
  }
]