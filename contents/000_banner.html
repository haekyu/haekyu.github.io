<div class="container">
  <div class="row">
    <div class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5">
      <div class="profile">
        <img class="profile-img" src="assets/images/profile-image.jpg">
        <div class="profile-contact">
          <div class="profile-contact-item">
            <a href="mailto:hkpark627@gmail.com">
              <i class="fa-solid fa-envelope"></i>
              hkpark627@gmail.com
            </a>
          </div>
          <div class="profile-contact-item">
            <a href="https://haekyu.com/assets/haekyu_cv.pdf">
              <i class="fa-solid fa-file"></i>
              CV
            </a>
          </div>
          <div class="profile-contact-item">
            <a href="https://scholar.google.com/citations?user=Nsmmp-cAAAAJ">
              <i class="fa-solid fa-graduation-cap"></i>
              Google Scholar
            </a>
          </div>
        </div>
      </div>
    </div>
    <div class="col-12 col-sm-12 col-md-7 col-lg-7 col-xl-7 col-xxl-7">
      <section>
        <h1>Haekyu Park</h1>
        <div class="intro">
          I'm a Machine Learning Researcher/Engineer, focusing on ML interpretability and human-centered AI development. 
          <br> <br>
          I received Ph.D. in Computer Science at Georgia Tech, advised by Dr. Polo Chau, aiming to make 
          ML models more interpretable, trustworthy, and safe.
          My PhD research aimed to bridge the gap between complex deep neural networks (DNNs) and intuitive human understanding,
          through a comprehensive human-centered interpretation of their inner workings, evolution, and vulnerabilities: 
          <ul>
            <li> How can we make sense of complex DNNs, by uncovering and summarizing the concepts they learn? </li>
            <li> How do these concepts form and evolve during training?</li>
            <li> When DNNs are at risk from potential threats, how do we identify and explain their vulnerabilities? </li>
          </ul>
          My research was supported by <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship-2021">JPMorgan AI PhD Fellowship</a>. 
          <br> <br>
          After completing my PhD, I worked as a Machine Learning Engineer at Stripe, where I extended my interests in building
          AI models for safety and security. At Stripe, I developed advanced ML models to detect potential fraud 
          in high-stakes financial environments, gaining valuable experience in handling adversarial transaction patterns.
          <br> <br>
          I have been fortunate to work with amazing researchers, engineers, and scientists at Stripe, Microsoft, NVIDIA, and Intel.
        </div>
      </section>
    </div>
  </div>
</div>