<section class="resume-section p-3 p-lg-5 d-flex flex-column">
  <div class="my-auto">
    <h2 class="mb-5">Publication</h2>

    <h3 class="mb-5">2020</h3>

    <!-- Massif -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Conference [3]</font> -->
        <h5 class="mb-0">
          Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning
        </h5>
        <div class="subheading mb-3">
          <a href="http://nilakshdas.com"><font color="868e96">Nilaksh Das*</font></a>,
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u>*</font></a>,
          <a href="https://zijie.wang/"><font color="868e96">Zijie Jay Wang</font></a>,
          <a href="https://fredhohman.com"><font color="868e96">Fred Hohman</font></a>,
          <a href="https://www.robfirstman.com/"><font color="868e96">Robert Firstman</font></a>,
          <a href="https://www.linkedin.com/in/emily-rogers-1a828598"><font color="868e96">Emily Rogers</font></a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a><br>
          ACM CHI Conference on Human Factors in Computing Systems (CHI),
          <a href="https://chi2020.acm.org/authors/late-breaking-works/">Late-Breaking Works</a>, 2020,
          Honolulu, Hawaii, USA <br>
          * Authors contributed equally. <br>
          <!-- <a href="https://fredhohman.com/papers/summit">[Website]</a> -->
          <!-- <a href="https://fredhohman.com/summit/">[Demo]</a> -->
          <!-- <a href="https://fredhohman.com/papers/19-summit-vast.pdf">[PDF]</a> -->
          <a href="https://arxiv.org/abs/2001.07769">[arXiv]</a>
          <a href=#none onclick=toggle_block('bibtex-massif');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-massif');>[Details]</a>
          <pre id='bibtex-massif' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @article{das2020massif,
              title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
              author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Horng, Duen and others},
              journal={arXiv preprint arXiv:2001.07769},
              year={2020}
            }
          </pre>
          <div id='detail-massif' style="text-align:justify; display:none;">
            <br>
            We are developing Massif, an interactive tool for deciphering adversarial attacks. Massif identifies and interactively visualizes neurons and their connections inside a DNN that are strongly activated or suppressed by an adversarial attack. Massif provides both a high-level, interpretable overview of the effect of an attack on a DNN, and a low-level, detailed description of the affected neurons. These tightly coupled views in Massif help people better understand which input features are most vulnerable or important for correct predictions.
          </div>
        </div>
      </div>
    </div>
    <!-- Massif END -->

    <!-- CNN101 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Conference [3]</font> -->
        <h5 class="mb-0">
          CNN 101: Interactive Visual Learning for Convolutional Neural Networks
        </h5>
        <div class="subheading mb-3">
          <a href="https://zijie.wang/"><font color="868e96">Zijie Jay Wang</font></a>,
          <a href="https://www.linkedin.com/in/robert-turko/"><font color="868e96">Robert Turko</font></a>,
          <a href="http://oshaikh.com/"><font color="868e96">Omar Shaikh</font></a>,
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>,
          <a href="http://nilakshdas.com"><font color="868e96">Nilaksh Das</font></a>,
          <a href="https://fredhohman.com"><font color="868e96">Fred Hohman</font></a>,
          <a href="https://minsuk.com/"><font color="868e96">Minsuk Kahng</font></a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a><br>
          ACM CHI Conference on Human Factors in Computing Systems (CHI),
          <a href="https://chi2020.acm.org/authors/late-breaking-works/">Late-Breaking Works</a>, 2020,
          Honolulu, Hawaii, USA <br>
          <a href="https://arxiv.org/pdf/2001.02004.pdf">[arXiv]</a>
          <a href=#none onclick=toggle_block('bibtex-cnn101');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-cnn101');>[Details]</a>
          <pre id='bibtex-cnn101' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @article{wang_cnn_2020,
              title = {{CNN} 101: {Interactive} {Visual} {Learning} for {Convolutional} {Neural} {Networks}},
              shorttitle = {{CNN} 101},
              url = {http://arxiv.org/abs/2001.02004},
              urldate = {2020-01-08},
              journal = {arXiv:2001.02004 [cs]},
              author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
              month = jan,
              year = {2020},
              note = {arXiv: 2001.02004},
              keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning}
          }
          </pre>
          <div id='detail-cnn101' style="text-align:justify; display:none;">
            <br>
            The success of deep learning solving previously-thought hard problems has inspired many non-experts to learn and understand this exciting technology. However, it is often challenging for learners to take the first steps due to the complexity of deep learning models. We present our ongoing work, CNN 101, an interactive visualization system for explaining and teaching convolutional neural networks. Through tightly integrated interactive views, CNN 101 offers both overview and detailed descriptions of how a model works. Built using modern web technologies, CNN 101 runs locally in users' web browsers without requiring specialized hardware, broadening the public's education access to modern deep learning techniques.
          </div>
        </div>
      </div>
    </div>
    <!-- CNN101 END -->


    <h3 class="mb-5">2019</h3>

    <!-- Summit -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Conference [3]</font> -->
        <h5 class="mb-0">
          Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations
        </h5>
        <div class="subheading mb-3">
          <a href="https://fredhohman.com"><font color="868e96">Fred Hohman</font></a>,
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>,
          <a href="http://calebrob.com"><font color="868e96">Caleb Robinson</font></a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a><br>
          IEEE VIS 
          <!-- Conference on Visual Analytics Science and Technology -->
          (<a href="http://ieeevis.org/year/2019/welcome">VAST</a>), 2019,
          Vancouver, BC, Canada <br>
          <a href="https://fredhohman.com/papers/summit">[Website]</a>
          <a href="https://fredhohman.com/summit/">[Demo]</a>
          <a href="https://fredhohman.com/papers/19-summit-vast.pdf">[PDF]</a>
          <a href="https://arxiv.org/abs/1904.02323">[arXiv]</a>
          <a href=#none onclick=toggle_block('bibtex-summit');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-summit');>[Details]</a>
          <pre id='bibtex-summit' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @article{hohman2020summit,
              title={Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations},
              author={Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng},
              journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},
              year={2020},
              publisher={IEEE}
              url={https://fredhohman.com/summit/}
            }
          </pre>
          <div id='detail-summit' style="text-align:justify; display:none;">
            <br>
            With Summit, users can scalably summarize and interactively interpret deep neural networks by visualizing what features a network detects and how they are related. In this example, InceptionV1 accurately classifies images of tench (yellow-brown fish). However, Summit reveals surprising associations in the network (e.g., using parts of people) that contribute to its final outcome: the "tench" prediction is dependent on an intermediate "hands holding fish" feature (right callout), which is influenced by lower-level features like "scales," "person," and "fish". A. The Embedding View summarizes all classes' aggregated activations using dimensionality reduction. B. The Class Sidebar enables users to search, sort, and compare all classes within a model. C. The Attribution Graph View visualizes highly activated neurons as vertices ("scales" "fish") and their most influential connections as edges (dashed purple edges).
          </div>
        </div>
      </div>
    </div>
    <!-- Summit END -->

    <!-- WiML 2019 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Other [2]</font> -->
        <h5 class="mb-0">
          Visual Analytics for Interpretability on Deep Neural Networks
        </h5>
        <div class="subheading mb-3">
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>,
          <a href="https://fredhohman.com"><font color="868e96">Fred Hohman</font></a>,
          <a href="http://nilakshdas.com"><font color="868e96">Nilaksh Das</font></a>,
          <a href="http://calebrob.com"><font color="868e96">Caleb Robinson</font></a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a><br>
          Women in Machine Learning Workshop (co-located with NeurIPS 2019)
          (<a href="http://ieeevis.org/year/2019/welcome">WiML</a>), 2019,
          Vancouver, BC, Canada <br>
        </div>
      </div>
    </div>
    <!-- WiML 2019 END -->

    <!-- MLsploit2 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Other [1]</font> -->
        <h5 class="mb-0">
          MLsploit: A Framework for Interactive Experimentation with Adversarial Machine Learning Research
        </h5>
        <div class="subheading mb-3">
          <a href="http://nilakshdas.com"><font color="868e96">Nilaksh Das</font></a>,
          <a href="https://rsli.github.io"><font color="868e96">Siwei Li</font></a>,
          <font color="868e96">Chanil Jeon</font>,
          <font color="868e96">Jinho Jung</font>,
          <font color="868e96">Shang-Tse Chen</font>,
          <font color="868e96">Carter Yagemann</font>,
          <font color="868e96">Evan Downing</font>,
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>,
          <font color="868e96">Evan Yang</font>,
          <font color="868e96">Li Chen</font>,
          <font color="868e96">Michael Kounavis</font>,
          <font color="868e96">Ravi Sahita</font>,
          <font color="868e96">David Durham</font>,
          <font color="868e96">Scott Buck</font>,
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a>,
          <a href="https://taesoo.kim"><font color="868e96">Taesoo Kim</font></a>, and
          <a href="http://wenke.gtisc.gatech.edu"><font color="868e96">Wenke Lee</font></a>
          <br>
          ACM SIGKDD Conference on Konwledge Discovery and Data Mining (KDD),
          <a href="KDD Project Showcase, 2019, https://www.kdd.org/kdd2019/project-showcase">KDD Project</a>, 2019,
          Anchorage, Alaska, USA <br>
          <a href="https://www.kdd.org/kdd2019/docs/KDD2019_Showcase_2062.pdf">[PDF]</a>
        </div>
      </div>
    </div>
    <!-- MLsploit2 END -->


    <!-- MLsploit -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Other [1]</font> -->
        <h5 class="mb-0">
          MLsploit: A Cloud-Based Framework for Adversarial Machine Learning Research 
        </h5>
        <div class="subheading mb-3">
          <a href="http://nilakshdas.com"><font color="868e96">Nilaksh Das</font></a>,
          <a href="https://rsli.github.io"><font color="868e96">Siwei Li</font></a>,
          <font color="868e96">Chanil Jeon</font>,
          <font color="868e96">Jinho Jung</font>,
          <font color="868e96">Shang-Tse Chen</font>,
          <font color="868e96">Carter Yagemann</font>,
          <font color="868e96">Evan Downing</font>,
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>,
          <font color="868e96">Evan Yang</font>,
          <font color="868e96">Li Chen</font>,
          <font color="868e96">Michael Kounavis</font>,
          <font color="868e96">Ravi Sahita</font>,
          <font color="868e96">David Durham</font>,
          <font color="868e96">Scott Buck</font>,
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a>,
          <a href="https://taesoo.kim"><font color="868e96">Taesoo Kim</font></a>, and
          <a href="http://wenke.gtisc.gatech.edu"><font color="868e96">Wenke Lee</font></a>
          <br>
          Black Hat Asia - Arsenal, 2019
          <br>
          <a href="https://www.blackhat.com/asia-19/arsenal/schedule/index.html#mlsploit-a-cloud-based-framework-for-adversarial-machine-learning-research-14256">[Abstract]</a>
          <a href="https://mlsploit.github.io">[Project]</a>
          <a href="https://youtu.be/hlzszoQVgD4">[Video]</a>
        </div>
      </div>
    </div>
    <!-- MLsploit END -->

    <!-- NeuralDivergence -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Poster [1]</font> -->
        <h5 class="mb-0">
          NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions
        </h5>
        <div class="subheading mb-3">
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>
          <a href="https://fredhohman.com"><font color="868e96">Fred Hohman</font></a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/"><font color="868e96">Duen Horng Chau</font></a><br>
          IEEE Pacific Visualization Symposium
          (<a href="http://research.cbs.chula.ac.th/pvis2019/home.aspx">PacificVis</a>), 2019,
          Bangkok, Thailand <br>
          <a href="assets/papers/19-pacificvis-neural-divergence.pdf">[PDF]</a>
          <a href="http://haekyu.com/neural-divergence/">[Website]</a>
          <a href="https://arxiv.org/abs/1906.00332">[arXiv]</a>
          <a href=#none onclick=toggle_block('bibtex-neuraldivergence');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-neuraldivergence');>[Details]</a>
          <pre id='bibtex-neuraldivergence' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @inproceedings{park2019neuraldivergence,
              title={NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions},
              author={Park, Haekyu and Hohman, Fred and Chau, Duen Horng},
              booktitle={Poster, Pacific Visualization Symposium (PacificVis)},
              year={2019},
              publisher={IEEE},
              url={http://haekyu.com/neural-divergence/}
            }
          </pre>
          <div id='detail-neuraldivergence' style="text-align:justify; display:none;">
            <br>
            As deep neural networks are increasingly used in solving high-stake problems, there is a pressing need to understand their internal decision mechanisms. Visualization has helped address this problem by assisting with interpreting complex deep neural networks. However, current tools often support only single data instances, or visualize layers in isolation. We present NeuralDivergence, an interactive visualization system that uses activation distributions as a high-level summary of what a model has learned. NeuralDivergence enables users to interactively summarize and compare activation distributions across layers, classes, and instances (e.g., pairs of adversarial attacked and benign images), helping them gain better understanding of neural network models.
          </div>
        </div>
      </div>
    </div>
    <!-- NeuralDivergence END -->

    <h3 class="mb-5">2018</h3>

    <!-- SIDE -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Conference [2]</font> -->
        <h5 class="mb-0">
          SIDE: Representation Learning in Signed Directed Networks
        </h5>
        <div class="subheading mb-3">
          <a href="http://junghwanjkim.com"><font color="868e96">Junghwan Kim</font></a>, 
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>, 
          <a href="https://jieunparklee.github.io"><font color="868e96">Ji-Eun Lee</font></a>, and 
          <a href="https://datalab.snu.ac.kr/~ukang/"><font color="868e96">U Kang</font></a><br>
          The Web Conference 
          (Previously known as <a href="https://www2018.thewebconf.org">WWW</a>, World Wide Web Conference) 2018,
          Lyon, France <br>
          <a href="assets/papers/18-www-side.pdf">[PDF]</a>
          <a href="https://datalab.snu.ac.kr/side/">[Website]</a>
          <a href=#none onclick=toggle_block('bibtex-side');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-side');>[Details]</a>
          <pre id='bibtex-side' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @inproceedings{KimPLK18,
                author    = {Junghwan Kim and
                             Haekyu Park and
                             Ji{-}Eun Lee and
                             U. Kang},
                title     = {{SIDE:} Representation Learning in Signed Directed Networks},
                booktitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web,
                             {WWW} 2018, Lyon, France, April 23-27, 2018},
                pages     = {509--518},
                year      = {2018},
              }
          </pre>
          <div id='detail-side' style="text-align:justify; display:none;">
            <br>
            We propose SIDE, a network embedding algorithm for signed directed networks. Network embedding learns a mapping of each node to a vector. SIDE carefully formulates and optimizes likelihood over both direct and indirect signed connections. We provide socio-psychological interpretation for each component of likelihood function and prove linear scalability of our algorithm.
          </div>
        </div>
      </div>
    </div>
    <!-- SIDE END -->


    <h3 class="mb-5">2017</h3>

    <!-- MFRWR -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        <!-- <font color="#BD5D38">Conference [1]</font> -->
        <h5 class="mb-0">
          A Comparative Study of Matrix Factorization and Random Walk with Restart in Recommender Systems 
        </h5>
        <div class="subheading mb-3">
          <a href="https://haekyu.github.io"><font color="868e96"><u>Haekyu Park</u></font></a>, 
          <a href="https://datalab.snu.ac.kr/~jinhong/"><font color="868e96">Jinhong Jung</font></a>, and 
          <a href="https://datalab.snu.ac.kr/~ukang/"><font color="868e96">U Kang</font></a><br>
          IEEE International Conference on Big Data 
          (<a href="http://cci.drexel.edu/bigdata/bigdata2017/">BigData</a>) 
          2017, Boston, MA, USA <br>
          <a href="assets/papers/17-bigdata-compare-mf-rwr.pdf">[PDF]</a>
          <a href="https://datalab.snu.ac.kr/mfrwr/">[Website]</a>
          <a href="https://arxiv.org/abs/1708.09088">[arXiv]</a>
          <a href="https://datalab.snu.ac.kr/mfrwr/resources/mfrwr.pptx">[Slides]</a>
          <a href=#none onclick=toggle_block('bibtex-mfrwr');>[BibTeX]</a>
          <a href=#none onclick=toggle_block('detail-mfrwr');>[Details]</a>
          <pre id='bibtex-mfrwr' style="display: none; transform: translate(-155px, 15px); font-size: 15px">
            @inproceedings{conf/bigdataconf/ParkJK17,
                author    = {Haekyu Park and
                             Jinhong Jung and
                             U. Kang},
                title     = {A comparative study of matrix factorization and random walk with restart
                             in recommender systems},
                booktitle = {2017 {IEEE} International Conference on Big Data, BigData 2017, Boston,
                             MA, USA, December 11-14, 2017},
                pages     = {756--765},
                year      = {2017},
              }
          </pre>
          <div id='detail-mfrwr' style="text-align:justify; display:none;">
            <br>
            <ul class="no-list work">
              <li> <b>Main Question</b>:<br> 
                  Between matrix factorization (<b>MF</b>) or Random Walk with Restart (<b>RWR</b>), 
                  which method works better for recommender systems?
              <li> <b>Specific tasks</b>:<br>
                  We compare MF and RWR for the following recommendation scenarios.
                  <ul class="no-list work">
                    <li> Which method performs better when using <b>explicit feedback</b> data?</li>
                    &rarr; MF is better.
                    <li> Which method performs better when using <b>implicit feedback</b> data?</li>
                    &rarr; RWR is better.
                    <li> Do global <b>bias</b> terms improve performance?</li>
                    &rarr; Yes.
                    <li> Which method performs better when exploiting global <b>bias</b> terms?</li>
                    &rarr; MF is better.
                    <li> Does <b>side information</b> enhance performance?</li>
                    &rarr; Yes with explicit ratings, and No with implicit ratings.
                    <li> Which method performs better when employing <b>side information</b>? </li>
                    &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.
                    <li> Which method solves the <b>cold start problem</b> better when employing <b>side data</b>? </li>
                    &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.
                  </ul>
              <li> <b>Discussion</b>:<br>
                What are the <b>reasons</b> for good or bad performance of MF and RWR in various settings of recommendations?
                Details are in Section 4.G in our paper. Please read that part!
          </div>
      </div>


    </div>
    <!-- MFRWR END -->
    

  </div>

</section>