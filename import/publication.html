<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.min.css" />

<section class="resume-section p-3 p-lg-5 d-flex flex-column">
  <br>
  <div class="my-auto">
    <h2 class="mb-5">Publication</h2>

    <h3 class="mb-5">2021</h3>

    <!-- SkeletonVis -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models
        </h5>
        
        <div class="authors subheading">
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          Anindya S. Paul,
          Pruthvi Perumalla,
          Zhiyan Zhou, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          <a href="https://aaai.org/Conferences/AAAI-21/">AAAI</a>, Demo,
          Virtual, 2021. <br>
        </div>
      </div>
    </div>
    <!-- SkeletonVis END -->

    <h3 class="mb-5">2020</h3>

    <!-- Bluff -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks
        </h5>
        
        <div class="authors subheading">
          <a href="http://nilakshdas.com">Nilaksh Das*</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u>*</a>,
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="https://www.robfirstman.com/">Robert Firstman</a>,
          <a href="https://www.linkedin.com/in/emily-rogers-1a828598">Emily Rogers</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          IEEE Visualization Conference,
          (<a href="http://ieeevis.org/year/2020/welcome">VIS</a>),
          Salt Lake City, UT, USA, 2020. <br>
          * Authors contributed equally.
        </div>

        <div class="publication-link subheading">
          <a href="https://poloclub.github.io/bluff">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="https://arxiv.org/abs/2009.02608">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/abs/2009.02608">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-bluff');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-bluff');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-bluff' class='bibtex' style='display: none;'>
            @article{das2020bluff,
              title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},
              author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
              booktitle={IEEE Visualization Conference (VIS)},
              year={2020}
            }
          </pre>
          <div id='detail-bluff' class='detail' style='display: none;'>
            Bluff is an interactive system for visualizing, characterizing, and deciphering adversarial attacks on vision-based neural networks.
            Bluff allows people to flexibly visualize and compare the activation pathways for benign and attacked images, revealing mechanisms that adversarial attacks employ to inflict harm on a model.
            Bluff is open-sourced and runs in modern web browsers.
          </div>
        </div>

      </div>
    </div>
    <!-- Bluff END -->

    <!-- CNN Explainer -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization
        </h5>
        
        <div class="authors subheading">
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="https://www.linkedin.com/in/robert-turko/">Robert Turko</a>,
          <a href="https://oshaikh.com/">Omar Shaikh</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="https://minsuk.com/">Minsuk Kahng</a>,
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          IEEE Conference on Visual Analytics Science and Technology,
          (<a href="http://ieeevis.org/year/2020/welcome">VAST</a>),  
          Salt Lake City, UT, USA, 2020. <br>
        </div>

        <div class="publication-link subheading">
          <a href="https://poloclub.github.io/cnn-explainer/">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="https://arxiv.org/pdf/2004.15004.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-cnnexplainer');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-cnnexplainer');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-cnnexplainer' class='bibtex' style='display: none;'>
            @article{wangCNNExplainerLearning2020,
              title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},
              shorttitle = {{{CNN Explainer}}},
              author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
              year = {2020},
              journal={IEEE Conference on Visual Analytics Science and Technology (VAST)},
              publisher={IEEE}
            }
          </pre>
          <div id='detail-cnnexplainer' class='detail' style='display: none;'>
            We present CNN Explainer, an interactive visualization tool designed for non-experts to learn and examine convolutional neural networks (CNNs), a foundational deep learning model architecture. Our tool addresses key challenges that novices face while learning about CNNs, which we identify from interviews with instructors and a survey with past students. CNN Explainer tightly integrates a model overview that summarizes a CNN’s structure, and on-demand, dynamic visual explanation views that help users understand the underlying components of CNNs. Through smooth transitions across levels of abstraction, our tool enables users to inspect the interplay between low-level mathematical operations and high-level model structures. A qualitative user study shows that CNN EXPLAINER helps users more easily understand the inner workings of CNNs, and is engaging and enjoyable to use. We also derive design lessons from our study. Developed using modern web technologies, CNN EXPLAINER runs locally in users’ web browsers without the need for installation or specialized hardware, broadening the public’s education access to modern deep learning techniques.
          </div>
        </div>

      </div>
    </div>
    <!-- CNN Explainer END -->

    <!-- Survey -->
    <!-- <br><br> -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          A Comparative Analysis of Industry Human-AI Interaction Guidelines
        </h5>
        
        <div class="authors subheading">
          <a href="https://www.austinpwright.com/">Austin P. Wright</a>,
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="https://gracegsy.github.io/">Grace Guo</a>,
          <a href="https://www.vis.uni-konstanz.de/mitglieder/sperrle/">Fabian Sperrle</a>,
          <a href="https://el-assady.com/">Mennatallah El-Assady</a>,
          <a href="https://va.gatech.edu/endert/">Alex Endert</a>
          <a href="https://www.vis.uni-konstanz.de/en/members/keim">Daniel Keim</a>
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          IEEE Visualization Conference, Workshop on Trust and Expertise in Visual Analytics (TREX), 
          Salt Lake City, UT, USA, 2020. <br>
        </div>

        <div class="publication-link subheading">
          <a href="https://arxiv.org/abs/2010.11761">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-survey');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-survey');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-survey' class='bibtex' style='display: none;'>
            @article{wrightComparativeAnalysisIndustry2020,
              title = {A {{Comparative Analysis}} of {{Industry Human}}-{{AI Interaction Guidelines}}},
              author = {Wright, Austin P. and Wang, Zijie J. and Park, Haekyu and Guo, Grace and Sperrle, Fabian and {El-Assady}, Mennatallah and Endert, Alex and Keim, Daniel and Chau, Duen Horng},
              year = {2020},
              month = oct,
              eprint = {2010.11761},
              journal = {arXiv:2010.11761}
            }
          </pre>
          <div id='detail-survey' class='detail' style='display: none;'>
            With the recent release of AI interaction guidelines from Apple, Google, and Microsoft, there is clearly interest in understanding the best practices in human-AI interaction. However, industry standards are not determined by a single company, but rather by the synthesis of knowledge from the whole community. We have surveyed all of the design guidelines from each of these major companies and developed a single, unified structure of guidelines, giving developers a centralized reference. We have then used this framework to compare each of the surveyed companies to find differences in areas of emphasis. Finally, we encourage people to contribute additional guidelines from other companies, academia, or individuals, to provide an open and extensible reference of AI design guidelines at https://ai-open-guidelines.readthedocs.io/en/latest/.
          </div>
        </div>

      </div>
    </div>
    <!-- Survey END -->

    <!-- Argo -->
    <!-- <div class='pagebreak'></div> -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers
        </h5>
        
        <div class="authors subheading">
          <a href="https://rsli.github.io/">Siwei Li</a>,
          <a href="https://www.linkedin.com/in/frank-zhou-b19515159/">Zhiyan Zhou</a>,
          Anish Upadhayay,
          <a href="https://oshaikh.com/">Omar Shaikh</a>,
          <a href="https://scottfreitas.com">Scott Freitas</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          Susanta Routray,
          Matthew Hull, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          ACM International Conference on Information and Knowledge Management,
          (<a href="https://www.cikm2020.org/">CIKM</a>), Resource Track, 
          Online, 2020. <br>
        </div>

        <div class="publication-link subheading">
          <a href="https://poloclub.github.io/argo-graph-lite/">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <!-- <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-argo');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-argo');>
            <i class="fas fa-info"></i>
            Details
          </a> -->
          <!-- <pre id='bibtex-argo' class='bibtex' style='display: none;'>
            @article{das2020massif,
              title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
              author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Horng, Duen and others},
              journal={arXiv preprint arXiv:2001.07769},
              year={2020}
            }
          </pre>
          <div id='detail-argo' class='detail' style='display: none;'>
            We are developing Massif, an interactive tool for deciphering adversarial attacks. Massif identifies and interactively visualizes neurons and their connections inside a DNN that are strongly activated or suppressed by an adversarial attack. Massif provides both a high-level, interpretable overview of the effect of an attack on a DNN, and a low-level, detailed description of the affected neurons. These tightly coupled views in Massif help people better understand which input features are most vulnerable or important for correct predictions.
          </div> -->
        </div>

      </div>
    </div>
    <!-- Argo END -->

    <!-- Massif -->
    <!-- <br><br><br><br> -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning
        </h5>
        
        <div class="authors subheading">
          <a href="http://nilakshdas.com">Nilaksh Das*</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u>*</a>,
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="https://www.robfirstman.com/">Robert Firstman</a>,
          <a href="https://www.linkedin.com/in/emily-rogers-1a828598">Emily Rogers</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          ACM CHI Conference on Human Factors in Computing Systems (CHI),
          <a href="https://chi2020.acm.org/authors/late-breaking-works/">Late-Breaking Works</a>, 
          Honolulu, Hawaii, USA, 2020. <br>
          * Authors contributed equally.
        </div>

        <div class="publication-link subheading">
          <a href="assets/papers/20-chi-massif.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/abs/2001.07769">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-massif');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-massif');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-massif' class='bibtex' style='display: none;'>
            @article{das2020massif,
              title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
              author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
              journal={arXiv preprint arXiv:2001.07769},
              year={2020}
            }
          </pre>
          <div id='detail-massif' class='detail' style='display: none;'>
            We are developing Massif, an interactive tool for deciphering adversarial attacks. Massif identifies and interactively visualizes neurons and their connections inside a DNN that are strongly activated or suppressed by an adversarial attack. Massif provides both a high-level, interpretable overview of the effect of an attack on a DNN, and a low-level, detailed description of the affected neurons. These tightly coupled views in Massif help people better understand which input features are most vulnerable or important for correct predictions.
          </div>
        </div>

      </div>
    </div>
    <!-- Massif END -->

    <!-- CNN101 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          CNN 101: Interactive Visual Learning for Convolutional Neural Networks
        </h5>

        <div class="authors subheading">
          <a href="https://zijie.wang/">Zijie J. Wang</a>,
          <a href="https://www.linkedin.com/in/robert-turko/">Robert Turko</a>,
          <a href="http://oshaikh.com/">Omar Shaikh</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="https://minsuk.com/">Minsuk Kahng</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          ACM CHI Conference on Human Factors in Computing Systems (CHI),
          <a href="https://chi2020.acm.org/authors/late-breaking-works/">Late-Breaking Works</a>,
          Honolulu, Hawaii, USA, 2020.
        </div>

        <div class="publication-link subheading">
          <a href="assets/papers/20-chi-cnn101.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/pdf/2001.02004.pdf">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-cnn101');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-cnn101');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-cnn101' class='bibtex' style='display: none;'>
            @article{wang_cnn_2020,
              title = {{CNN} 101: {Interactive} {Visual} {Learning} for {Convolutional} {Neural} {Networks}},
              shorttitle = {{CNN} 101},
              url = {http://arxiv.org/abs/2001.02004},
              urldate = {2020-01-08},
              journal = {arXiv:2001.02004 [cs]},
              author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
              month = jan,
              year = {2020},
              note = {arXiv: 2001.02004},
              keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning}
          }
          </pre>
          <div id='detail-cnn101' class='detail' style='display: none;'>
            CNN 101 is an interactive visualization system for explaining and teaching convolutional neural networks. Through tightly integrated interactive views, CNN 101 offers both overview and detailed descriptions of how a model works. Built using modern web technologies, CNN 101 runs locally in users' web browsers without requiring specialized hardware, broadening the public's education access to modern deep learning techniques.
          </div>
        </div>
      </div>
    </div>
    <!-- CNN101 END -->


    <h3 class="mb-5">2019</h3>

    <!-- Summit -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations
        </h5>

        <div class="authors subheading">
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="http://calebrob.com">Caleb Robinson</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          IEEE Transactions on Visualization and Computer Graphics
          (<a href="http://ieeevis.org/year/2019/welcome">TVCG</a>),
          Vancouver, BC, Canada, 2020.
        </div>

        <div class="publication-link subheading">
          <a href="https://fredhohman.com/summit/">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="https://fredhohman.com/papers/19-summit-vast.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/abs/1904.02323">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-summit');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-summit');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-summit' class='bibtex' style="display: none;">
            @article{hohman2020summit,
              title={Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations},
              author={Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng},
              journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},
              year={2020},
              publisher={IEEE}
              url={https://fredhohman.com/summit/}
            }
          </pre>
          <div id='detail-summit' class='detail' style="display:none;">
            With Summit, users can scalably summarize and interactively interpret deep neural networks by visualizing what features a network detects and how they are related. For example, InceptionV1 accurately classifies images of tench (yellow-brown fish). However, Summit reveals surprising associations in the network (e.g., using parts of people) that contribute to its final outcome: the "tench" prediction is dependent on an intermediate "hands holding fish" feature, which is influenced by lower-level features like "scales," "person," and "fish".
          </div>
        </div>
      </div>
    </div>
    <!-- Summit END -->

    <!-- WiML 2019 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        
        <h5>
          Visual Analytics for Interpretability on Deep Neural Networks
        </h5>

        <div class="authors subheading">
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          <a href="https://fredhohman.com">Fred Hohman</a>,
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          <a href="http://calebrob.com">Caleb Robinson</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          Women in Machine Learning Workshop (<a href="http://ieeevis.org/year/2019/welcome">WiML</a>),
          co-located with NeurIPS 2019, Vancouver, BC, Canada, 2019.
        </div>

      </div>
    </div>
    <!-- WiML 2019 END -->

    <!-- MLsploit2 -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        
        <h5>
          MLsploit: A Framework for Interactive Experimentation with Adversarial Machine Learning Research
        </h5>

        <div class="authors subheading">
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          <a href="https://rsli.github.io">Siwei Li</a>,
          Chanil Jeon,
          Jinho Jung,
          Shang-Tse Chen,
          Carter Yagemann,
          Evan Downing,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          Evan Yang,
          Li Chen,
          Michael Kounavis,
          Ravi Sahita,
          David Durham,
          Scott Buck,
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>,
          <a href="https://taesoo.kim">Taesoo Kim</a>, and
          <a href="http://wenke.gtisc.gatech.edu">Wenke Lee</a>
        </div>

        <div class="venue subheading">
          ACM SIGKDD Conference on Konwledge Discovery and Data Mining (KDD),
          <a href="KDD Project Showcase, 2019, https://www.kdd.org/kdd2019/project-showcase">KDD Project</a>, Anchorage, Alaska, USA, 2019.
        </div>

        <div class="publication-link subheading">
          <a href="https://mlsploit.github.io">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="https://www.kdd.org/kdd2019/docs/KDD2019_Showcase_2062.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
        </div>

      </div>
    </div>
    <!-- MLsploit2 END -->


    <!-- MLsploit -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        
        <h5>
          MLsploit: A Cloud-Based Framework for Adversarial Machine Learning Research 
        </h5>

        <div class="authors subheading">
          <a href="http://nilakshdas.com">Nilaksh Das</a>,
          <a href="https://rsli.github.io">Siwei Li</a>,
          Chanil Jeon,
          Jinho Jung,
          Shang-Tse Chen,
          Carter Yagemann,
          Evan Downing,
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>,
          Evan Yang,
          Li Chen,
          Michael Kounavis,
          Ravi Sahita,
          David Durham,
          Scott Buck,
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>,
          <a href="https://taesoo.kim">Taesoo Kim</a>, and
          <a href="http://wenke.gtisc.gatech.edu">Wenke Lee</a>
        </div>

        <div class="venue subheading">
          Black Hat Asia - Arsenal, 2019.
        </div>

        <div class="publication-link subheading">
          <a href="https://mlsploit.github.io">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="https://www.blackhat.com/asia-19/arsenal/schedule/index.html#mlsploit-a-cloud-based-framework-for-adversarial-machine-learning-research-14256">
            <i class="far fa-file-alt"></i>
            Abstract
          </a>
          <a href="https://youtu.be/hlzszoQVgD4">
            <i class="fas fa-video"></i>
            Video
          </a>
        </div>

      </div>
    </div>
    <!-- MLsploit END -->

    <!-- NeuralDivergence -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        
        <h5>
          NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions
        </h5>

        <div class="authors subheading">
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>
          <a href="https://fredhohman.com">Fred Hohman</a>, and 
          <a href="https://www.cc.gatech.edu/~dchau/">Duen Horng Chau</a>
        </div>

        <div class="venue subheading">
          IEEE Pacific Visualization Symposium
          (<a href="http://research.cbs.chula.ac.th/pvis2019/home.aspx">PacificVis</a>), 
          Bangkok, Thailand, 2019.
        </div>

        <div class="publication-link subheading">
          <a href="http://haekyu.com/neural-divergence/">
            <i class="fas fa-play"></i>
            Demo
          </a>
          <a href="assets/papers/19-pacificvis-neural-divergence.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/abs/1906.00332">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-neuraldivergence');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href'onclick=toggle_block('detail-neuraldivergence');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-neuraldivergence' class='bibtex' style="display: none;">
            @inproceedings{park2019neuraldivergence,
              title={NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions},
              author={Park, Haekyu and Hohman, Fred and Chau, Duen Horng},
              booktitle={Poster, Pacific Visualization Symposium (PacificVis)},
              year={2019},
              publisher={IEEE},
              url={http://haekyu.com/neural-divergence/}
            }
          </pre>
          <div id='detail-neuraldivergence' class='detail' style="display:none;">
            NeuralDivergence is an interactive visualization system that uses activation distributions as a high-level summary of what a model has learned. NeuralDivergence enables users to interactively summarize and compare activation distributions across layers, classes, and instances (e.g., pairs of adversarial attacked and benign images), helping them gain better understanding of neural network models.
          </div>
        </div>
      </div>
    </div>
    <!-- NeuralDivergence END -->

    <h3 class="mb-5">2018</h3>

    <!-- SIDE -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">

        <h5>
          SIDE: Representation Learning in Signed Directed Networks
        </h5>

        <div class="authors subheading">
          <a href="http://junghwanjkim.com">Junghwan Kim</a>, 
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>, 
          <a href="https://jieunparklee.github.io">Ji-Eun Lee</a>, and 
          <a href="https://datalab.snu.ac.kr/~ukang/">U Kang</a>
        </div>

        <div class="venue subheading">
          The Web Conference 
          (Previously known as <a href="https://www2018.thewebconf.org">WWW</a>, World Wide Web Conference), 
          Lyon, France, 2018.
        </div>

        <div class="publication-link subheading">
          <a href="https://datalab.snu.ac.kr/side/">
            <i class="fas fa-layer-group"></i>
            Project
          </a>
          <a href="assets/papers/18-www-side.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-side');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-side');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-side' class='bibtex' style="display: none;">
            @inproceedings{KimPLK18,
                author    = {Junghwan Kim and
                             Haekyu Park and
                             Ji{-}Eun Lee and
                             U. Kang},
                title     = {{SIDE:} Representation Learning in Signed Directed Networks},
                booktitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web,
                             {WWW} 2018, Lyon, France, April 23-27, 2018},
                pages     = {509--518},
                year      = {2018},
              }
          </pre>
          <div id='detail-side' class='detail', style="display:none;">
            We propose SIDE, a network embedding algorithm for signed directed networks. Network embedding learns a mapping of each node to a vector. SIDE carefully formulates and optimizes likelihood over both direct and indirect signed connections. We provide socio-psychological interpretation for each component of likelihood function and prove linear scalability of our algorithm.
          </div>
        </div>
      </div>
    </div>
    <!-- SIDE END -->


    <h3 class="mb-5">2017</h3>

    <!-- MFRWR -->
    <div class="resume-item d-flex flex-column flex-md-row mb-5">
      <div class="resume-content mr-auto">
        
        <h5>
          A Comparative Study of Matrix Factorization and Random Walk with Restart in Recommender Systems 
        </h5>

        <div class="authors subheading">
          <a href="https://haekyu.github.io"><u>Haekyu Park</u></a>, 
          <a href="https://datalab.snu.ac.kr/~jinhong/">Jinhong Jung</a>, and 
          <a href="https://datalab.snu.ac.kr/~ukang/">U Kang</a>
        </div>

        <div class="venue subheading">
          IEEE International Conference on Big Data 
          (<a href="http://cci.drexel.edu/bigdata/bigdata2017/">BigData</a>), 
          Boston, MA, USA, 2017.
        </div>

        <div class="publication-link subheading">
          <a href="https://datalab.snu.ac.kr/mfrwr/">
            <i class="fas fa-layer-group"></i>
            Project
          </a>
          <a href="assets/papers/17-bigdata-compare-mf-rwr.pdf">
            <i class="far fa-file-pdf"></i>
            PDF
          </a>
          <a href="https://arxiv.org/abs/1708.09088">
            <i class="far fa-file-alt"></i>
            arXiv
          </a>
          <a href=#none class='bibtex-href' onclick=toggle_block('bibtex-mfrwr');>
            <i class="far fa-bookmark"></i> 
            BibTeX
          </a>
          <a href=#none class='detail-href' onclick=toggle_block('detail-mfrwr');>
            <i class="fas fa-info"></i>
            Details
          </a>
          <pre id='bibtex-mfrwr' class='bibtex' style="display: none;">
            @inproceedings{conf/bigdataconf/ParkJK17,
                author    = {Haekyu Park and
                             Jinhong Jung and
                             U. Kang},
                title     = {A comparative study of matrix factorization and random walk with restart
                             in recommender systems},
                booktitle = {2017 {IEEE} International Conference on Big Data, BigData 2017, Boston,
                             MA, USA, December 11-14, 2017},
                pages     = {756--765},
                year      = {2017},
              }
          </pre>
          <div id='detail-mfrwr' class='detail' style="display:none;">
            <ul class="no-list work">
              <li> <b>Main Question</b>:<br> 
                  Between matrix factorization (<b>MF</b>) or Random Walk with Restart (<b>RWR</b>), 
                  which method works better for recommender systems?
              <li> <b>Specific tasks</b>:<br>
                  We compare MF and RWR for the following recommendation scenarios.
                  <ul class="no-list work">
                    <li> Which method performs better when using <b>explicit feedback</b> data?</li>
                    &rarr; MF is better.
                    <li> Which method performs better when using <b>implicit feedback</b> data?</li>
                    &rarr; RWR is better.
                    <li> Do global <b>bias</b> terms improve performance?</li>
                    &rarr; Yes.
                    <li> Which method performs better when exploiting global <b>bias</b> terms?</li>
                    &rarr; MF is better.
                    <li> Does <b>side information</b> enhance performance?</li>
                    &rarr; Yes with explicit ratings, and No with implicit ratings.
                    <li> Which method performs better when employing <b>side information</b>? </li>
                    &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.
                    <li> Which method solves the <b>cold start problem</b> better when employing <b>side data</b>? </li>
                    &rarr; MF is better with explicit rating data, and RWR is better with implicit rating data.
                  </ul>
              <li> <b>Discussion</b>:<br>
                What are the <b>reasons</b> for good or bad performance of MF and RWR in various settings of recommendations?
                Details are in Section 4.G in our paper. Please read that part!
          </div>
      </div>


    </div>
    <!-- MFRWR END -->
    

  </div>

</section>

